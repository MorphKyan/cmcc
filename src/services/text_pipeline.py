import asyncio
import json
from loguru import logger
from langchain_core.messages import HumanMessage

from src.api.context import Context
from src.core import dependencies
from src.module.input.stream_decoder import StreamDecoder
from src.module.llm.tool.definitions import ExhibitionCommand, CommandAction
from src.services.aep_client import get_aep_client
from src.module.rag.base_rag_processor import MetadataType

class TextPipelineService:
    """
    Service for handling text-driven pipeline requests.
    This allows testing the RAG -> LLM -> Command Execution flow without audio input.
    """

    @staticmethod
    async def get_context(client_id: str) -> Context:
        """
        Get or create a Context for the given client_id.
        For text pipeline, we reuse the same context to maintain chat history.
        """
        if client_id in dependencies.active_contexts:
            return dependencies.active_contexts[client_id]
        
        # Create new context if not exists
        logger.info(f"Creating new context for text pipeline: {client_id}")
        decoder = StreamDecoder()
        # Ensure VAD core is available (it should be initialized in lifespan)
        if dependencies.vad_core is None:
             raise RuntimeError("VAD Core is not initialized")
             
        context = Context(context_id=client_id, decoder=decoder, vad_core=dependencies.vad_core)
        dependencies.active_contexts[client_id] = context
        return context

    @staticmethod
    async def process_text(text: str, client_id: str = "text_pipeline") -> dict:
        """
        Process a text command through the RAG and LLM pipeline.
        
        Args:
            text: The user's input text.
            client_id: The client identifier (default: "text_pipeline").
            
        Returns:
            A dictionary containing the execution results.
        """
        logger.info(f"Processing text pipeline request for {client_id}: {text}")
        
        context = await TextPipelineService.get_context(client_id)
        
        # 1. RAG Retrieval
        rag_settings = dependencies.rag_processor.settings
        
        # Execute retrievals in parallel
        # door_docs_task = dependencies.rag_processor.retrieve_context(
        #     text, metadata_types=[MetadataType.DOOR], top_k=rag_settings.door_top_k
        # )
        media_docs_task = dependencies.rag_processor.retrieve_context(
            text, metadata_types=[MetadataType.MEDIA], top_k=rag_settings.media_top_k
        )
        device_docs_task = dependencies.rag_processor.retrieve_context(
            text, metadata_types=[MetadataType.DEVICE], top_k=rag_settings.device_top_k
        )
        
        video_docs, device_docs = await asyncio.gather(
            media_docs_task, device_docs_task
        )
        door_docs = []
        
        retrieved_docs_by_type = {
            "door": door_docs,
            "video": video_docs,
            "device": device_docs
        }
        
        # 2. LLM Processing
        chat_history_messages = context.chat_history
        
        # Use existing method to get response and commands
        ai_message, commands, tool_messages = await dependencies.llm_processor.get_response_with_retries(
            user_input=text,
            rag_docs=retrieved_docs_by_type,
            user_location=context.location,
            chat_history=chat_history_messages
        )
        
        # Update chat history
        context.chat_history.append(HumanMessage(content=text))
        context.chat_history.append(ai_message)
        if tool_messages:
            context.chat_history.extend(tool_messages)
            
        # 3. Command Execution
        execution_results = []
        
        if not commands:
            logger.info("No commands generated by LLM")
            return {
                "success": True,
                "message": "No commands generated",
                "ai_response": ai_message.content,
                "commands": [],
                "results": []
            }

        # Execute commands (similar to audio_pipeline but synchronous result collection)
        # Note: We reuse the logic from audio_pipeline roughly but we can't directly reuse functions 
        # because they are tied to websockets. We'll implement direct execution here.
        
        # 3.1 Local Commands
        local_commands = [cmd for cmd in commands if cmd.action == CommandAction.UPDATE_LOCATION.value]
        for cmd in local_commands:
            result = await TextPipelineService._execute_local_command(cmd, context)
            execution_results.append(result)
            
        # 3.2 remote Commands (AEP)
        remote_commands = [cmd for cmd in commands if cmd.action != CommandAction.UPDATE_LOCATION.value]
        for cmd in remote_commands:
            result = await TextPipelineService._execute_aep_command(cmd, context)
            execution_results.append(result)
            
        return {
            "success": True,
            "ai_response": ai_message.content,
            "commands": [cmd.model_dump() for cmd in commands],
            "results": execution_results
        }

    @staticmethod
    async def _execute_local_command(cmd: ExhibitionCommand, context: Context) -> dict:
        """Execute local command (update location)."""
        if cmd.action == CommandAction.UPDATE_LOCATION.value and cmd.params:
            old_location = context.location
            context.location = cmd.params
            logger.info(f"[位置更新] {old_location} -> {cmd.params}")
            return {
                "success": True,
                "action": cmd.action,
                "message": f"位置从「{old_location}」更新为「{cmd.params}」" if old_location else f"位置设置为「{cmd.params}」"
            }
        return {
            "success": False,
            "action": cmd.action,
            "message": f"未知的本地命令：{cmd.action}"
        }

    @staticmethod
    async def _execute_aep_command(cmd: ExhibitionCommand, context: Context) -> dict:
        """Execute command via AEP Client."""
        try:
            aep_client = get_aep_client()
            response = await aep_client.send_voice_command(
                name=cmd.device_name,
                type_=cmd.device_type,
                sub_type=cmd.sub_type,
                view=cmd.view,
                command=cmd.command,
                param=cmd.params,
                resource=cmd.resource,
            )

            if response.success:
                if response.device_name:
                    context.last_device_name = response.device_name

                # Update location based on device area
                device_info = dependencies.data_service.get_device_info(cmd.device_name)
                if device_info:
                    device_area = device_info.get("area", "")
                    if device_area:
                        old_location = context.location
                        context.location = device_area
                        logger.info(f"[位置更新] 根据设备区域: {old_location} -> {device_area}")

                return {
                    "success": True,
                    "action": cmd.action,
                    "message": f"设备「{cmd.device_name}」执行「{cmd.command}」",
                    "aep_response": response.model_dump()
                }
            else:
                return {
                    "success": False,
                    "action": cmd.action,
                    "message": response.message,
                    "aep_response": response.model_dump()
                }

        except Exception as e:
            error_msg = f"AEP API调用失败: {str(e)}"
            logger.exception("[AEP] 命令执行异常")
            return {
                "success": False,
                "action": cmd.action,
                "message": error_msg
            }
